# WiFi Intrusion Detection System

WiFi aÄŸlarÄ±nda saldÄ±rÄ± tespiti iÃ§in makine Ã¶ÄŸrenimi tabanlÄ± sistem. AWID2 veri seti kullanÄ±larak Ã§eÅŸitli sÄ±nÄ±flandÄ±rma algoritmalarÄ±nÄ±n performanslarÄ±nÄ± K-Fold cross validation, undersampling ve SMOTE teknikleri ile karÅŸÄ±laÅŸtÄ±rÄ±r.

## Proje AÃ§Ä±klamasÄ±

Bu proje, WiFi aÄŸ trafiÄŸini analiz ederek aÅŸaÄŸÄ±daki saldÄ±rÄ± tÃ¼rlerini tespit etmeyi amaÃ§lar:
- **Normal**: Yasal WiFi trafiÄŸi
- **Flooding**: AÄŸ kaynaklarÄ±nÄ± tÃ¼keten saldÄ±rÄ±lar
- **Impersonation**: Kimlik sahtekarlÄ±ÄŸÄ± saldÄ±rÄ±larÄ±

Proje, veri dengesizliÄŸi problemini Ã§Ã¶zmek iÃ§in undersampling ve SMOTE tekniklerini kullanÄ±r ve model performansÄ±nÄ± K-Fold cross validation ile deÄŸerlendirir.

## Gereksinimler

```bash
pip install pandas numpy matplotlib scikit-learn seaborn lightgbm imbalanced-learn
```

### Gerekli KÃ¼tÃ¼phaneler:
- `pandas` - Veri manipÃ¼lasyonu
- `numpy` - SayÄ±sal hesaplamalar
- `matplotlib` - GÃ¶rselleÅŸtirme
- `scikit-learn` - Makine Ã¶ÄŸrenimi algoritmalarÄ±
- `seaborn` - Ä°statistiksel gÃ¶rselleÅŸtirme
- `lightgbm` - Gradient boosting algoritmasÄ±
- `imbalanced-learn` - Veri dengeleme teknikleri (SMOTE)

## Veri Seti

**AWID2 (Aegean WiFi Intrusion Dataset)** kullanÄ±lmaktadÄ±r:
- **EÄŸitim Seti**: `AWID-CLS-R-Trn/1`
- **Test Seti**: `AWID-CLS-R-Tst/1`
- **Ã–zellik SayÄ±sÄ±**: 154 (16 seÃ§ili Ã¶zellik kullanÄ±lÄ±yor)
- **Veri DengesizliÄŸi**: Normal sÄ±nÄ±f diÄŸer sÄ±nÄ±flardan Ã§ok daha fazla Ã¶rnek iÃ§erir

### SeÃ§ili Ã–zellikler:
- Frame Ã¶zellikleri: `frame.len`
- Radiotap Ã¶zellikleri: `radiotap.length`, `radiotap.channel.freq`, `radiotap.dbm_antsignal`
- WLAN Ã¶zellikleri: `wlan.duration`, `wlan.fc.type`, `wlan.fc.subtype`, vb.

## KullanÄ±lan Algoritmalar

1. **Decision Tree** - Karar aÄŸacÄ± algoritmasÄ±
2. **LightGBM** - Gradient boosting algoritmasÄ±
3. **Logistic Regression** - Lojistik regresyon
4. **SGD Classifier** - Stokastik gradyan iniÅŸ
5. **Linear SVC** - Destek vektÃ¶r makinesi
6. **Random Forest** - Rastgele orman
7. **Extra Trees** - Ekstra aÄŸaÃ§lar

## Veri Dengeleme Teknikleri

### 1. K-Fold Cross Validation
- **Stratified K-Fold** (k=10) kullanÄ±lÄ±r
- SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ± koruyarak veriyi bÃ¶ler
- Her fold'da eÄŸitim ve test setlerinin sÄ±nÄ±f oranlarÄ± korunur
- Model performansÄ±nÄ±n daha gÃ¼venilir deÄŸerlendirilmesini saÄŸlar

### 2. Undersampling
- Ã‡oÄŸunluk sÄ±nÄ±fÄ±ndan (Normal) rastgele Ã¶rnekler Ã§Ä±karÄ±r
- HÄ±zlÄ± iÅŸlem sÃ¼resi saÄŸlar
- Veri kaybÄ±na neden olabilir ancak dengeyi saÄŸlar

### 3. SMOTE (Synthetic Minority Oversampling Technique)
- AzÄ±nlÄ±k sÄ±nÄ±flarÄ± iÃ§in sentetik Ã¶rnekler Ã¼retir
- K-nearest neighbors algoritmasÄ± kullanÄ±r
- Veri kaybÄ± olmadan sÄ±nÄ±f dengesini saÄŸlar
- Overfitting riskini azaltÄ±r

## KullanÄ±m

### 1. Veri HazÄ±rlama
```python
# Veri setini yÃ¼kle
awid2trn_data = pd.read_csv("path/to/train/data", header=None, names=features)
awid2tst_data = pd.read_csv("path/to/test/data", header=None, names=features)

# SeÃ§ili Ã¶zellikleri filtrele
awid2trn_data = awid2trn_data.loc[:, selected_features + ['class']]
```

### 2. Veri Ã–n Ä°ÅŸleme
```python
# NaN deÄŸerleri temizle
data = data.replace(r'^\s*$', pd.NA, regex=True)
data = data.replace('?', pd.NA)
data = data.dropna()

# Injection sÄ±nÄ±fÄ±nÄ± kaldÄ±r
filter_data = data['class'] != 'injection'
data = data[filter_data]
```

### 3. Ã–zellik MÃ¼hendisliÄŸi
```python
# Sinyal gÃ¼cÃ¼ dÃ¶nÃ¼ÅŸÃ¼mÃ¼
X['radiotap.dbm_antsignal'] = X['radiotap.dbm_antsignal'].apply(convert_to_integer)

# Min-Max Ã¶lÃ§eklendirme
scaler = MinMaxScaler()
X[columns_to_scale] = scaler.fit_transform(X[columns_to_scale])

# One-hot encoding
X = pd.get_dummies(X, columns=columns_to_one_hot_encode)
```


### 4. Model EÄŸitimi ve DeÄŸerlendirme
```python
# 10-Fold Cross Validation fonksiyonu
def train_and_evaluate_model(model, X, y, kfold, model_name=""):
    accumulated_metrics = {
        'accuracy': [], 'f1_macro': [], 'f1_micro': [], 'f1_weighted': [],
        'precision_macro': [], 'precision_micro': [], 'precision_weighted': [],
        'recall_macro': [], 'recall_micro': [], 'recall_weighted': [], 'auc': []
    }
    
    for train_index, test_index in kfold.split(X, y):
        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y.iloc[train_index], y.iloc[test_index]
        
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        
        metrics = calculate_metrics(y_test, y_pred, model, X_test)
        for key in accumulated_metrics.keys():
            accumulated_metrics[key].append(metrics.get(key, np.nan))
    
    return accumulated_metrics
```

## DeÄŸerlendirme Metrikleri

### Temel Metrikler
- **Accuracy** - DoÄŸruluk oranÄ±
- **F1-Score** (Macro, Micro, Weighted)
  - **Macro**: Her sÄ±nÄ±fÄ±n eÅŸit aÄŸÄ±rlÄ±kta deÄŸerlendirilmesi
  - **Micro**: TÃ¼m Ã¶rneklerin eÅŸit aÄŸÄ±rlÄ±kta deÄŸerlendirilmesi
  - **Weighted**: SÄ±nÄ±f boyutlarÄ±na gÃ¶re aÄŸÄ±rlÄ±klandÄ±rÄ±lmÄ±ÅŸ deÄŸerlendirme
- **Precision** (Macro, Micro, Weighted)
- **Recall** (Macro, Micro, Weighted)
- **AUC-ROC** - ROC eÄŸrisi altÄ±ndaki alan

### GÃ¶rselleÅŸtirme
- **Confusion Matrix** - KarÄ±ÅŸÄ±klÄ±k matrisi (3x3 matrix: Normal, Flooding, Impersonation)
- **Performance Comparison Charts** - FarklÄ± dengeleme yÃ¶ntemlerinin karÅŸÄ±laÅŸtÄ±rmasÄ±

## Ã–nemli Fonksiyonlar

### `convert_to_integer(value)`
Birden fazla sinyal gÃ¼cÃ¼ deÄŸerini ortalama deÄŸere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.

### `calculate_metrics(y_test, y_pred, model, X_test)`
Model performans metriklerini hesaplar (accuracy, F1-score, precision, recall, AUC).

### `train_and_evaluate_model(model, X, y, kfold, model_name)`
- K-Fold cross validation gerÃ§ekleÅŸtirir
- Her fold iÃ§in model eÄŸitir ve test eder
- Ortalama performans metriklerini hesaplar
- KarÄ±ÅŸÄ±klÄ±k matrisini oluÅŸturur

### `plot_confusion_matrix(cm, model_name)`
KarÄ±ÅŸÄ±klÄ±k matrisini heatmap olarak gÃ¶rselleÅŸtirir.

## Model Hiperparametreleri

### Decision Tree
```python
DecisionTreeClassifier(
    max_depth=20,
    ccp_alpha=0.001,
    max_leaf_nodes=100,
    min_samples_leaf=2,
    random_state=42
)
```

### LightGBM
```python
LGBMClassifier(
    objective='multiclass',
    num_leaves=20,
    learning_rate=0.01,
    max_depth=10,
    n_estimators=80,
    reg_alpha=0.01,
    reg_lambda=0.01
)
```

### Random Forest
```python
RandomForestClassifier(
    max_depth=20,
    ccp_alpha=0.001,
    max_leaf_nodes=100,
    min_samples_leaf=2,
    random_state=42
)
```

### Extra Trees
```python
ExtraTreesClassifier(
    max_depth=200,
    n_estimators=200,
    ccp_alpha=0.0001,
    max_leaf_nodes=500,
    min_samples_leaf=2,
    min_samples_split=10,
    random_state=42
)
```

## Dengeleme YÃ¶ntemleri KarÅŸÄ±laÅŸtÄ±rmasÄ±

| YÃ¶ntem | Avantajlar | Dezavantajlar | KullanÄ±m Durumu |
|--------|------------|---------------|-----------------|
| **Original** | GerÃ§ek veri daÄŸÄ±lÄ±mÄ± | SÄ±nÄ±f dengesizliÄŸi | Baseline karÅŸÄ±laÅŸtÄ±rma |
| **Undersampling** | HÄ±zlÄ± iÅŸlem, basit | Veri kaybÄ± | BÃ¼yÃ¼k veri setleri |
| **SMOTE** | Veri kaybÄ± yok, sentetik Ã§eÅŸitlilik | Hesaplama maliyeti, overfitting riski | KÃ¼Ã§Ã¼k-orta veri setleri |

## Beklenen Performans SonuÃ§larÄ±

### Dengesiz Veri Seti
- Normal sÄ±nÄ±f iÃ§in yÃ¼ksek precision/recall
- AzÄ±nlÄ±k sÄ±nÄ±flarÄ± iÃ§in dÃ¼ÅŸÃ¼k recall
- Genel accuracy yÃ¼ksek ama yanÄ±ltÄ±cÄ±

### Undersampling SonrasÄ±
- Dengeli precision/recall deÄŸerleri
- AzÄ±nlÄ±k sÄ±nÄ±flarÄ± iÃ§in iyileÅŸtirilmiÅŸ performans
- DÃ¼ÅŸÃ¼k genel accuracy ancak daha adil deÄŸerlendirme

### SMOTE SonrasÄ±
- En dengeli performans metrikleri
- TÃ¼m sÄ±nÄ±flar iÃ§in optimize edilmiÅŸ F1-score
- GerÃ§ekÃ§i ve gÃ¼venilir model performansÄ±

## K-Fold Cross Validation AvantajlarÄ±

1. **GÃ¼venilir DeÄŸerlendirme**: 10 farklÄ± train/test bÃ¶lÃ¼nmesi ile robust sonuÃ§lar
2. **Overfitting KontrolÃ¼**: Model genelleme yeteneÄŸinin test edilmesi
3. **Stratified Sampling**: SÄ±nÄ±f daÄŸÄ±lÄ±mÄ±nÄ±n her fold'da korunmasÄ±
4. **Ä°statistiksel AnlamlÄ±lÄ±k**: Ortalama ve standart sapma ile gÃ¼ven aralÄ±klarÄ±


## Ã–nemli Notlar

- **Veri Yolu**: Google Colab kullanÄ±yorsanÄ±z Drive yollarÄ±nÄ± gÃ¼ncelleyin
- **Bellek KullanÄ±mÄ±**: SMOTE bÃ¼yÃ¼k veri setlerinde yÃ¼ksek bellek kullanabilir
- **Ä°ÅŸlem SÃ¼resi**: K-Fold CV ile iÅŸlem sÃ¼releri uzayabilir
- **SÄ±nÄ±f Dengeleme**: GerÃ§ek dÃ¼nya uygulamalarÄ±nda uygun yÃ¶ntemi seÃ§in
- **Hiperparametre Optimizasyonu**: Grid Search ile daha iyi sonuÃ§lar alÄ±nabilir

## KatkÄ±da Bulunma

1. Fork yapÄ±n
2. Feature branch oluÅŸturun (`git checkout -b feature/BalancingMethod`)
3. DeÄŸiÅŸikliklerinizi commit edin (`git commit -m 'Add SMOTE implementation'`)
4. Branch'inizi push edin (`git push origin feature/BalancingMethod`)
5. Pull Request oluÅŸturun


## ğŸ“§ Ä°letiÅŸim

SorularÄ±nÄ±z iÃ§in lÃ¼tfen issue aÃ§Ä±n.

---

**Not**: Bu proje akademik amaÃ§lÄ± geliÅŸtirilmiÅŸtir. GerÃ§ek Ã¼retim ortamÄ±nda kullanmadan Ã¶nce ek gÃ¼venlik testleri ve model validasyonu yapÄ±lmalÄ±dÄ±r.